{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
    "y = weight * X + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        self.weights = nn.Parameter(torch.randn(1,\n",
    "            requires_grad=True,\n",
    "            dtype=torch.float\n",
    "        ))\n",
    "\n",
    "        self.bias = nn.Parameter(torch.randn(1,\n",
    "            requires_grad=True,\n",
    "            dtype=torch.float\n",
    "        ))\n",
    "\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.weights * x + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.3367], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1288], requires_grad=True)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "model_0 = LinearRegressionModel()\n",
    "\n",
    "list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(),\n",
    "                            lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is: 0.340311199426651\n",
      "models state dict: OrderedDict([('weights', tensor([0.3413])), ('bias', tensor([0.1388]))])\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_0.train()\n",
    "    \n",
    "    y_pred = model_0(X_train)\n",
    "    \n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    \n",
    "    print(f'Loss is: {loss}')\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    model_0.eval()\n",
    "    \n",
    "    print(f'models state dict: {model_0.state_dict()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | MAE Train Loss: 0.3281443119049072 | MAE Test Loss: 0.3593423664569855 \n",
      "Epoch: 10 | MAE Train Loss: 0.20647522807121277 | MAE Test Loss: 0.231970876455307 \n",
      "Epoch: 20 | MAE Train Loss: 0.09646346420049667 | MAE Test Loss: 0.11382298171520233 \n",
      "Epoch: 30 | MAE Train Loss: 0.062241941690444946 | MAE Test Loss: 0.057641178369522095 \n",
      "Epoch: 40 | MAE Train Loss: 0.0508681945502758 | MAE Test Loss: 0.04030483216047287 \n",
      "Epoch: 50 | MAE Train Loss: 0.044844936579465866 | MAE Test Loss: 0.03354765847325325 \n",
      "Epoch: 60 | MAE Train Loss: 0.039243943989276886 | MAE Test Loss: 0.029139220714569092 \n",
      "Epoch: 70 | MAE Train Loss: 0.033642955124378204 | MAE Test Loss: 0.024730807170271873 \n",
      "Epoch: 80 | MAE Train Loss: 0.02804194949567318 | MAE Test Loss: 0.02032238245010376 \n",
      "Epoch: 90 | MAE Train Loss: 0.0224409531801939 | MAE Test Loss: 0.015913957729935646 \n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "train_loss_values = []\n",
    "test_loss_values = []\n",
    "epoch_count = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    \n",
    "    ### Training\n",
    "\n",
    "    model_0.train()\n",
    "    \n",
    "    y_pred = model_0(X_train)\n",
    "    \n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "\n",
    "    ### Testing\n",
    "\n",
    "    model_0.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "      test_pred = model_0(X_test)\n",
    "\n",
    "      test_loss = loss_fn(test_pred, y_test.type(torch.float))\n",
    "\n",
    "      if epoch % 10 == 0:\n",
    "            epoch_count.append(epoch)\n",
    "            train_loss_values.append(loss.detach().numpy())\n",
    "            test_loss_values.append(test_loss.detach().numpy())\n",
    "            print(f\"Epoch: {epoch} | MAE Train Loss: {loss} | MAE Test Loss: {test_loss} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "name": "train loss",
         "type": "scatter",
         "x": [
          0,
          10,
          20,
          30,
          40,
          50,
          60,
          70,
          80,
          90
         ],
         "xaxis": "x",
         "y": [
          0.3281443119049072,
          0.20647522807121277,
          0.09646346420049667,
          0.062241941690444946,
          0.0508681945502758,
          0.044844936579465866,
          0.039243943989276886,
          0.033642955124378204,
          0.02804194949567318,
          0.0224409531801939
         ],
         "yaxis": "y"
        },
        {
         "name": "test loss",
         "type": "scatter",
         "x": [
          0,
          10,
          20,
          30,
          40,
          50,
          60,
          70,
          80,
          90
         ],
         "xaxis": "x",
         "y": [
          0.3593423664569855,
          0.231970876455307,
          0.11382298171520233,
          0.057641178369522095,
          0.04030483216047287,
          0.03354765847325325,
          0.029139220714569092,
          0.024730807170271873,
          0.02032238245010376,
          0.015913957729935646
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.94
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ]
        },
        "yaxis2": {
         "anchor": "x",
         "overlaying": "y",
         "side": "right"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig_1 = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "fig_1.add_trace(\n",
    "    go.Scatter(x=epoch_count, y=train_loss_values, name=\"train loss\"),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "fig_1.add_trace(\n",
    "    go.Scatter(x=epoch_count, y=test_loss_values, name=\"test loss\"),\n",
    "    secondary_y=True,\n",
    ")\n",
    "\n",
    "fig_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = Path(\"./models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_NAME = \"pytorch_workflow_model_0.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the models state dict\n",
    "torch.save(obj=model_0.state_dict(),\n",
    "           f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model_0 = LinearRegressionModel()\n",
    "\n",
    "loaded_model_0.load_state_dict(torch.load(f=MODEL_SAVE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.6366])), ('bias', tensor([0.3323]))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear_layer.weight', tensor([[0.7645]])),\n",
       "             ('linear_layer.bias', tensor([0.8300]))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LinearRegressionModelV2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear_layer = nn.Linear(in_features=1,\n",
    "                                      out_features=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear_layer(x)\n",
    "        \n",
    "torch.manual_seed(42)\n",
    "model_1 = LinearRegressionModelV2()\n",
    "model_1.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.SGD(params=model_1.parameters(),\n",
    "                            lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Loss: 0.5478836894035339 | Test_Loss: 0.5424822568893433\n",
      "Epoch: 2 | Loss: 0.5357168316841125 | Test_Loss: 0.5297451615333557\n",
      "Epoch: 3 | Loss: 0.5235499143600464 | Test_Loss: 0.5170080065727234\n",
      "Epoch: 4 | Loss: 0.5113829970359802 | Test_Loss: 0.5042709112167358\n",
      "Epoch: 5 | Loss: 0.49921607971191406 | Test_Loss: 0.4915337562561035\n",
      "Epoch: 6 | Loss: 0.4870491921901703 | Test_Loss: 0.4787966310977936\n",
      "Epoch: 7 | Loss: 0.4748823046684265 | Test_Loss: 0.46605950593948364\n",
      "Epoch: 8 | Loss: 0.4627154767513275 | Test_Loss: 0.4533224105834961\n",
      "Epoch: 9 | Loss: 0.45054855942726135 | Test_Loss: 0.4405852258205414\n",
      "Epoch: 11 | Loss: 0.4262147545814514 | Test_Loss: 0.41511091589927673\n",
      "Epoch: 12 | Loss: 0.41404786705970764 | Test_Loss: 0.4023738503456116\n",
      "Epoch: 13 | Loss: 0.40188097953796387 | Test_Loss: 0.38963669538497925\n",
      "Epoch: 14 | Loss: 0.3897140622138977 | Test_Loss: 0.3768995404243469\n",
      "Epoch: 15 | Loss: 0.37754717469215393 | Test_Loss: 0.3641623854637146\n",
      "Epoch: 16 | Loss: 0.36538028717041016 | Test_Loss: 0.35142531991004944\n",
      "Epoch: 17 | Loss: 0.353213369846344 | Test_Loss: 0.3386881947517395\n",
      "Epoch: 18 | Loss: 0.3410464823246002 | Test_Loss: 0.3259510397911072\n",
      "Epoch: 19 | Loss: 0.32887959480285645 | Test_Loss: 0.31321391463279724\n",
      "Epoch: 21 | Loss: 0.3045458197593689 | Test_Loss: 0.287739634513855\n",
      "Epoch: 22 | Loss: 0.29237887263298035 | Test_Loss: 0.27500253915786743\n",
      "Epoch: 23 | Loss: 0.28021201491355896 | Test_Loss: 0.2622653841972351\n",
      "Epoch: 24 | Loss: 0.2680451273918152 | Test_Loss: 0.24952824413776398\n",
      "Epoch: 25 | Loss: 0.255878210067749 | Test_Loss: 0.23679116368293762\n",
      "Epoch: 26 | Loss: 0.24371135234832764 | Test_Loss: 0.2240539789199829\n",
      "Epoch: 27 | Loss: 0.23154444992542267 | Test_Loss: 0.21131686866283417\n",
      "Epoch: 28 | Loss: 0.2193775475025177 | Test_Loss: 0.19857971370220184\n",
      "Epoch: 29 | Loss: 0.20721065998077393 | Test_Loss: 0.1858426034450531\n",
      "Epoch: 31 | Loss: 0.182876855134964 | Test_Loss: 0.16036832332611084\n",
      "Epoch: 32 | Loss: 0.17070996761322021 | Test_Loss: 0.14763116836547852\n",
      "Epoch: 33 | Loss: 0.15854306519031525 | Test_Loss: 0.13489405810832977\n",
      "Epoch: 34 | Loss: 0.14637617766857147 | Test_Loss: 0.12215693295001984\n",
      "Epoch: 35 | Loss: 0.1342092752456665 | Test_Loss: 0.1094198003411293\n",
      "Epoch: 36 | Loss: 0.12204239517450333 | Test_Loss: 0.09668266773223877\n",
      "Epoch: 37 | Loss: 0.10987548530101776 | Test_Loss: 0.08394553512334824\n",
      "Epoch: 38 | Loss: 0.09770859777927399 | Test_Loss: 0.0712084025144577\n",
      "Epoch: 39 | Loss: 0.08554171025753021 | Test_Loss: 0.05847126245498657\n",
      "Epoch: 41 | Loss: 0.0613970048725605 | Test_Loss: 0.03812096640467644\n",
      "Epoch: 42 | Loss: 0.05202231928706169 | Test_Loss: 0.033232517540454865\n",
      "Epoch: 43 | Loss: 0.04672688990831375 | Test_Loss: 0.030764412134885788\n",
      "Epoch: 44 | Loss: 0.0433458611369133 | Test_Loss: 0.02874131128191948\n",
      "Epoch: 45 | Loss: 0.041170231997966766 | Test_Loss: 0.027160823345184326\n",
      "Epoch: 46 | Loss: 0.03973961994051933 | Test_Loss: 0.02604883909225464\n",
      "Epoch: 47 | Loss: 0.038740627467632294 | Test_Loss: 0.025381172075867653\n",
      "Epoch: 48 | Loss: 0.03774162381887436 | Test_Loss: 0.02471352182328701\n",
      "Epoch: 49 | Loss: 0.03685496374964714 | Test_Loss: 0.024393314495682716\n",
      "Epoch: 51 | Loss: 0.03528890013694763 | Test_Loss: 0.023848116397857666\n",
      "Epoch: 52 | Loss: 0.03463449329137802 | Test_Loss: 0.023548239842057228\n",
      "Epoch: 53 | Loss: 0.033986859023571014 | Test_Loss: 0.023195749148726463\n",
      "Epoch: 54 | Loss: 0.03341029956936836 | Test_Loss: 0.02284325286746025\n",
      "Epoch: 55 | Loss: 0.03283373638987541 | Test_Loss: 0.02249075099825859\n",
      "Epoch: 56 | Loss: 0.03225717321038246 | Test_Loss: 0.022138256579637527\n",
      "Epoch: 57 | Loss: 0.03168061375617981 | Test_Loss: 0.021785760298371315\n",
      "Epoch: 58 | Loss: 0.031107446178793907 | Test_Loss: 0.02138250507414341\n",
      "Epoch: 59 | Loss: 0.030551869422197342 | Test_Loss: 0.021029997617006302\n",
      "Epoch: 61 | Loss: 0.029435068368911743 | Test_Loss: 0.02022349275648594\n",
      "Epoch: 62 | Loss: 0.028874969109892845 | Test_Loss: 0.01982022449374199\n",
      "Epoch: 63 | Loss: 0.02831875905394554 | Test_Loss: 0.019467735663056374\n",
      "Epoch: 64 | Loss: 0.027762677520513535 | Test_Loss: 0.019064467400312424\n",
      "Epoch: 65 | Loss: 0.027202581986784935 | Test_Loss: 0.01866120658814907\n",
      "Epoch: 66 | Loss: 0.026642480865120888 | Test_Loss: 0.018257956951856613\n",
      "Epoch: 67 | Loss: 0.026085644960403442 | Test_Loss: 0.01790546253323555\n",
      "Epoch: 68 | Loss: 0.025530198588967323 | Test_Loss: 0.017502188682556152\n",
      "Epoch: 69 | Loss: 0.024970093742012978 | Test_Loss: 0.017098944634199142\n",
      "Epoch: 71 | Loss: 0.023852527141571045 | Test_Loss: 0.01634318195283413\n",
      "Epoch: 72 | Loss: 0.023297708481550217 | Test_Loss: 0.015939926728606224\n",
      "Epoch: 73 | Loss: 0.022737612947821617 | Test_Loss: 0.015536671504378319\n",
      "Epoch: 74 | Loss: 0.02217750996351242 | Test_Loss: 0.015133416280150414\n",
      "Epoch: 75 | Loss: 0.021619413048028946 | Test_Loss: 0.014780914410948753\n",
      "Epoch: 76 | Loss: 0.021065225824713707 | Test_Loss: 0.0143776535987854\n",
      "Epoch: 77 | Loss: 0.02050512470304966 | Test_Loss: 0.013974403962492943\n",
      "Epoch: 78 | Loss: 0.01994502544403076 | Test_Loss: 0.013571137562394142\n",
      "Epoch: 79 | Loss: 0.019386304542422295 | Test_Loss: 0.01321862917393446\n",
      "Epoch: 81 | Loss: 0.018272649496793747 | Test_Loss: 0.01241211872547865\n",
      "Epoch: 82 | Loss: 0.0177125483751297 | Test_Loss: 0.012008863501250744\n",
      "Epoch: 83 | Loss: 0.017153184860944748 | Test_Loss: 0.011656376533210278\n",
      "Epoch: 84 | Loss: 0.01660025678575039 | Test_Loss: 0.011253106407821178\n",
      "Epoch: 85 | Loss: 0.01604016125202179 | Test_Loss: 0.010849839076399803\n",
      "Epoch: 86 | Loss: 0.015480054542422295 | Test_Loss: 0.01044660247862339\n",
      "Epoch: 87 | Loss: 0.014920076355338097 | Test_Loss: 0.01009410060942173\n",
      "Epoch: 88 | Loss: 0.01436777226626873 | Test_Loss: 0.009690833278000355\n",
      "Epoch: 89 | Loss: 0.013807672075927258 | Test_Loss: 0.009287575259804726\n",
      "Epoch: 91 | Loss: 0.012687471695244312 | Test_Loss: 0.008481052704155445\n",
      "Epoch: 92 | Loss: 0.012134777382016182 | Test_Loss: 0.008128556422889233\n",
      "Epoch: 93 | Loss: 0.011575196869671345 | Test_Loss: 0.0077253105118870735\n",
      "Epoch: 94 | Loss: 0.011015091091394424 | Test_Loss: 0.007322037126868963\n",
      "Epoch: 95 | Loss: 0.010454991832375526 | Test_Loss: 0.006918794009834528\n",
      "Epoch: 96 | Loss: 0.009901663288474083 | Test_Loss: 0.006566286087036133\n",
      "Epoch: 97 | Loss: 0.009342707693576813 | Test_Loss: 0.0061630308628082275\n",
      "Epoch: 98 | Loss: 0.00878260750323534 | Test_Loss: 0.005759775638580322\n",
      "Epoch: 99 | Loss: 0.008222509175539017 | Test_Loss: 0.005356526467949152\n",
      "Epoch: 101 | Loss: 0.007110218517482281 | Test_Loss: 0.004600766114890575\n",
      "Epoch: 102 | Loss: 0.006550127174705267 | Test_Loss: 0.004197495989501476\n",
      "Epoch: 103 | Loss: 0.005990027450025082 | Test_Loss: 0.003794252872467041\n",
      "Epoch: 104 | Loss: 0.005435439758002758 | Test_Loss: 0.0034439831506460905\n",
      "Epoch: 105 | Loss: 0.004877740982919931 | Test_Loss: 0.0030384839046746492\n",
      "Epoch: 106 | Loss: 0.004317642189562321 | Test_Loss: 0.0026352405548095703\n",
      "Epoch: 107 | Loss: 0.0037575415335595608 | Test_Loss: 0.0022319734562188387\n",
      "Epoch: 108 | Loss: 0.003202323568984866 | Test_Loss: 0.001917463494464755\n",
      "Epoch: 109 | Loss: 0.0026452564634382725 | Test_Loss: 0.0014911473263055086\n",
      "Epoch: 111 | Loss: 0.0015250534052029252 | Test_Loss: 0.0006696999189443886\n",
      "Epoch: 112 | Loss: 0.0009699009242467582 | Test_Loss: 0.0011480569373816252\n",
      "Epoch: 113 | Loss: 0.0009075179696083069 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 114 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 115 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 116 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 117 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 118 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 119 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 121 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 122 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 123 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 124 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 125 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 126 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 127 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 128 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 129 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 131 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 132 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 133 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 134 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 135 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 136 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 137 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 138 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 139 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 141 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 142 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 143 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 144 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 145 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 146 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 147 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 148 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 149 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 151 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 152 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 153 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 154 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 155 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 156 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 157 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 158 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 159 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 161 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 162 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 163 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 164 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 165 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 166 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 167 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 168 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 169 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 171 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 172 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 173 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 174 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 175 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 176 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 177 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 178 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 179 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 181 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 182 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 183 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 184 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 185 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 186 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 187 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 188 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 189 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 191 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 192 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 193 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 194 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 195 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 196 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 197 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n",
      "Epoch: 198 | Loss: 0.010759826749563217 | Test_Loss: 0.0016480416525155306\n",
      "Epoch: 199 | Loss: 0.0014070778852328658 | Test_Loss: 0.011089062318205833\n"
     ]
    }
   ],
   "source": [
    "from operator import mod\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "epochs = 200\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    #Train\n",
    "    model_1.train()\n",
    "    y_pred = model_1(X_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    #Testing\n",
    "    model_1.eval()\n",
    "    with torch.inference_mode():\n",
    "        test_pred = model_1(X_test)\n",
    "        test_loss = loss_fn(test_pred, y_test)\n",
    "        \n",
    "    if epoch % 10:\n",
    "        print(f'Epoch: {epoch} | Loss: {loss} | Test_Loss: {test_loss}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba181f63e9d4d2546882c6557f001599fbd08286524a1352a15ceb4bcf4e5348"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
